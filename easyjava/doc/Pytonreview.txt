시작문자는 0 혹은 많은(\ w *), 종료 문자는 (0 또는 여러 문자 (\ w *) 혹은 동일한 문자가 뒤에 오는 문자(\ w))와 일치한다.
분할 과정이 계속되고, 최종적으로 얻은 결과 문자열은 lot이다.
이 문제를 피하기 위해 wordnet을 그것과 함께 임베드(embed) 할 수 있다.
단어를 동의어로 대체
단어를 동의어로 대체 예제
텍스트에 지프의 법칙(Zipf's law) 적용
지프의 법칙에 따르면 텍스트의 토큰 빈도는 정렬된 목록의 순위(rank) 혹은 위치(position)에 정비례한다.
이 법칙은 토큰이 언어로 배포되는 방법을 설명한다.
일부 토큰은 매우 자주 발생하며 일부는 중간 빈도로 발생하며 일부 토큰은 거의 발생하지 않는다.
위의 코드는 문서의 단어 빈도 대 순위 빈도를 구한다.(확인)
따라서 지프의 법칙이 순위와 단어의 빈도 간의 비례 관계를 봄으로써 모든 문서에 대해 유지되는지 여부를 확인할 수 있다.

Similarity measure(유사성 척도)
NLP 작업을 수행하는 데 사용할 수 있는 많은 유사성 척도가 있다.NLTK의 nltk.metrics 패키지는 다양한 NLP 작업을 수행하는 데 도움이 되는 다양한 평가 혹은 유사성 측도를 제공하는 데 사용된다.
훈련 파일(training file)에서 얻은 표준 점수를 사용한 개체명 인식기(named entity recognizer)의 출력을 분석하는 방법을 살펴보자.

2017.01.18

기본적으로 선택되지 않음여기에서 relate와 relation 간의 편집 거리를 계산할 때 세 가지 작업(1번의 치환 작업과 2번의 삽입 작업)이 수행된다.

suggestion과 calculation 간의 편집 거리를 계산하는 동안 7가지 작업(6번의 치환 작업과 1번의 삽입 작업)이 수행된다.

자카드 계수(Jaccard's coefficient) 혹은 타니모토 계수(Tanimoto coefficient)는 X와 Y의 두 세트의 오버랩 측정으로 정의될 수 있다.

2장

컴퓨터 언어학은 해석학, 소프트웨어 애플리케이션 및 사람들이 머신과 통신하는 상황에서 널리 사용되는 새로운 영역이다.
자연 언어 텍스트에서 수행할 수 있는 전처리 작업 혹은 계산을 이해하는 것이 중요하다.
여기에서 바이그램의 빈도를 10에서 다른 숫자로 변경할 수 있다.

2017.01.20

fourgrams을 생성하고 fourgrams의 빈도를 생성하려면 다음 코드가 사용된다.
지수 분류기라고도 하는
이 모듈에서는 모든 확률 분포가 훈련 데이터에 따라 고려된다.
이 모델은 두 가지 기능, 즉 입력 기능 및 결합 기능을 참조하는 데 사용된다.
입력 기능은 라벨이 없는 단어의 기능이라고 할 수 있다.
MLE는 텍스트에서 주어진 발생에 대한 확률 분포를 포함하는 freqdist를 생성하는 데 사용된다.

2017.01.24
observed state : 관찰이 가능한 상태
latent states : 은닉 상태
HMM 추정을 사용하여 테스트를 수행할 수 있다.
우리는 추정 법칙(estimator)을 테스트했다.
에드온 스무딩
1 대신에 알려지지 않은 단어의 개수에 다른 값을 더할 수 있으므로 알려지지 않은 단어를 처리할 수 있고 그 확률은 0이 아니다.
가짜 수(Pseudo count)는 알려지지 않은 단어의 수에 추가되어 확률이 0이 아닌 값(즉 1 혹은 0이 아닌 값)이다.
각 단어의 수를 정규화해야 한다.
Good Turing이 방법은 보이지 않는 객체의 확률을 예측하는 데 도움이 된다.
이 방법에서는 이항 분포(binomial distribution)가 우리의 관심 객체에 의해 나타난다.
Simple Good Turing은 선형 회귀(linear regression)에 의해 로그 공간에서 선형 라인(linear line)으로 빈도에서 빈도까지 근사치를 수행한다.
