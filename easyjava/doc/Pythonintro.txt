About the Authors

Deepti Chopra는 Banasthali University의 조교수이다. 그녀의 주요 연구 분야는 전산 언어학, 자연어 처리 및 인공 지능이다. 그녀는 영어에서 인도어를 위한 MT 엔진 개발에도 참여한다.(확인) 그녀는 여러 저널 및 컨퍼런스에 다양한 간행물이 있으며 여러 컨퍼런스 및 저널의 프로그램 위원회에서도 활동한다.

Nisheeth Joshi는 Banasthali University의 부교수로 근무한다. 그의 관심 분야는 전산 언어학, 자연 언어 처리 및 인공 지능이다. 그는 TDIL 프로그램, 정보 기술부(Department of Information Technology), Govt로 empaneled 전문가 중 하나이다. 인도의, 인도에서 언어 기술 기금과 연구(Language Technology Funding and Research)를 총괄하는 최고의 기관. 그는 다양한 저널 및 컨퍼런스의 여러 간행물을 보유하고 있으며 여러 컨퍼런스 및 저널의 프로그램위원회 및 편집 위원으로도 활동한다. 

Iti Mathur는 Banasthali University의 조교수이다. 그녀의 관심 분야는 전산 의미론 및 존재론적 엔지니어링이다. 이 외에도, 영어에서 인도어까지 MT 엔진 개발에 참여한다. 그녀는 TDIL 프로그램, 전자 정보 기술 부서(Department of Electronics and Information Technology)(DeitY), 인도의 언어 기술 기금과 연구를 총괄하는 최고의 기관인 인도의 Govt empaneled 전문가 중 하나이다. 그녀는 여러 학술지와 학술회의에 여러 간행물을 보유하고 있으며 여러 회의 및 저널의 프로그램위원회 및 편집위원회에서 활동한다.

우리는 자연 언어 처리 기반 책을 출판하려는 목표를 달성하기 위해 전해진 축복에 대해 감사의 말을 전하고 모든 친지와 친척에게 진심으로 감사하다.

About the Reviewer

Arturo Argueta는 현재 고성능 컴퓨팅 및 NLP 연구를 수행하는 박사이다. Arturo는 클러스터링 알고리즘, NLP에 대한 기계 학습 알고리즘 및 기계 번역에 대한 연구를 수행했다. 그는 영어, 독일어 및 스페인어에도 능숙하다.

Preface

이 책에서는 Python에서 NLP의 다양한 작업을 구현하는 방법과 NLP의 최신 연구 주제에 대한 통찰력을 얻을 것이다. 이 책은 학생과 연구원이 실제 애플리케이션을 기반으로 자신의 프로젝트를 생성하는 데 도움이되는 포괄적인 단계별 안내서이다.

What this book covers

1장, '문자열 작업'은 토큰화 및 정규화와 같은 텍스트에 대한 사전 처리 작업을 수행하는 방법과 다양한 문자열 매칭 방법을 설명한다.

2장, '통계 언어 모델링'에서는 단어 빈도를 계산하고 다양한 언어 모델링 기법을 수행하는 방법을 다룬다.

3장, '형태학 - Getting Our Feet Wet'에서는 스테머, 형태소 분석기 및 형태소 생성기를 개발하는 방법을 다룬다.

4장, '품사 태깅 - 단어 식별'에서는 품사 태깅 및 n-gram 접근을 포함한 통계적 모델링을 다룬다.

5장, '파싱 - 트레이닝 데이터 분석'에서는 트리 뱅크 구성, CFG 구성, CYK 알고리즘, 차트 구문 분석 알고리즘 및 음역의 개념에 대한 정보를 살펴본다.

6장, '의미 분석 - Meaning Matters'에서는 Shallow Semantic Analysis(즉, NER)과 WordNet을 사용하는 WSD의 개념과 애플리케이션에 대해 살펴본다.

7장, 'Sentiment Analysis - I Am Happy'에서는 감정 분석의 개념을 이해하고 적용하는 데 도움이 되는 정보를 제공한다.

8장, '정보 검색 - 정보 액세스'는 정보 검색 및 텍스트 요약의 개념을 이해하고 적용하는 데 도움이될 것이다.

9장, '담화 분석 - 아는 것은 믿는 것', 담화 분석 시스템과 해결 기반 시스템을 개발한다.

10장, 'NLP 시스템 평가 - 성능 분석'에서는 NLP 시스템을 평가하는 개념을 이해하고 적용하는 방법에 대해 살펴본다.

What you need for this book

모든 장에서 Python 2.7 혹은 3.2+가 사용된다. NLTK 3.0은 32 비트 머신 혹은 64 비트 머신에 설치해야한다. 필요한 운영 체제는 Windows/Mac/Unix이다.

Who this book is for

이 책은 합리적인 지식 수준과 Python에 대한 이해를 바탕으로 NLP의 중급 개발자를 대상으로 한다.

Conventions

이 책에서는 여러 종류의 정보를 구별하는 다양한 텍스트 스타일을 확인할 수 있다. 다음은 이러한 스타일의 예제와 그 의미에 대한 설명이다.

텍스트에서 코드 단어, 데이터베이스 테이블 이름, 폴더 이름, 파일 이름, 파일 확장자, 경로 이름, 더미 URL, 사용자 입력 및 Twitter 핸들은 다음과 같다.

"For tokenization of French text, we will use the french.pickle file."

코드 블록은 다음과 같이 설정된다.

<소스>

이와 같은 상자에 경고 혹은 중요한 메모가 나타난다.

팁과 트릭은 이와 같이 나타난다.

Page 107.

의미분석,
=>의미분석

문자 시퀀스
=>의미 분석은 문자 시퀀스

정의된다.
=>정의한다.

사용될 수 있다.
=>사용할 수 있다.

Page 108.

자연어
=> 자연 언어

실행할 수 있는 계산을
=> 계산을 실행하는 것을

수행된다.
=> 수행될 것이다.

의미분석 해석
=> 의미 해석

문장에서 의미를
=>의미를 문장에

콘텐츠 해석 ~ 매핑한다.
=>문맥 해석은 논리 형식을 지식 표현으로 매핑하는 것이다.

의미론적 분석의
=> 의미 분석의

나타낼 수 있다.
=>표현할 수 있다.

도움을 나타낼 수 있다.
=>도움으로 그것을 나타낼 수 있다.

개념에게 방법을 주었다.
=>스크립트의 개념으로 나아 갔다.

