Page 107.

6장. 의미 분석-Meaning Matters

의미 분석, 혹은 의미 생성은 NLP의 작업 중 하나이다. 문자 시퀀스 혹은 단어 시퀀스의 의미를 결정하는 과정으로 정의된다. 명료화 작업을 수행하기 위해 사용될 수 있다.

6장에서는 다음 주제를 살펴볼 것이다.

-NER
-HMM을 사용한 NER 시스템
-기계 학습 툴킷(machine learning toolkits)을 사용한 NER 훈련
-POS 태깅(POS tagging)을 사용한 NER
-Wordnet에서 synset id의 생성
-Wordnet을 사용한 명확한 감각(Disambiguating senses)

Page 108.

의미 분석 소개

NLP는 자연어에 대한 실행할 수 있는 계산을 의미한다. 자연어 처리하는 동안에 수행되는 단계 중 하나는 의미론적 분석이다. 입력 문장을 분석하는 동안, 문장의 구문 구조가 설계되면, 이 후에 문장의 의미 분석이 수행된다. 의미분석 해석은 문장에서 의미를 매핑하는 것을 의미한다.(확인) 콘텐츠 해석(Contextual interpretation)은 지식 표현의 논리 형태를 매핑한다. 의미론적 분석의 원시 혹은 기본 단위는 의미 혹은 감각으로 지칭된다. 감각을 다루는 도구 중 하나는 ELIZA이다. ELIZA는 조셉 바이첸바움(Joseph Weizenbaum)에 의해 60년대에 개발됐다. 치환과 문장을 분석하는 패턴 매칭 기술을 사용하고 주어진 입력에 출력을 제공한다. MARGIE는 70년대에 Robert Schank에 의해 개발됐다. 그것은 11 프리미티브(primitives)를 사용하여 모든 영어 동사를 나타낼 수 있다. MARGIE는 문장의 의미를 해석하고 프리미티브의 도움을 나타낼 수 있다. 그것은 게다가 스크립트의 개념에게 방법을 주었다. MARGIE에서 SAM(Script Applier Mechanism)이 개발됐다. 그것은 영어, 중국어, 러시아어, 네덜란드어, 스페인어 같은 다양한 언어의 문장을 번역할 수 있다. 텍스트 데이터에 대한 처리를 수행하기 위해, Python library 혹은 TextBlob이 사용된다. TextBlob는 품사 태깅, 명사구 추출, 분류, 기계 번역, 심리 분석과 같은 NLP 작업을 수행하기 위한 API를 제공한다.

의미 분석은 데이터베이스를 조회하고 정보를 검색하는 데 사용할 수 있다. 또 다른 파이썬 라이브러리(Python library), Gensim는 문서 인덱싱, 주제 모델링 및 유사도 검색을 수행하는데 사용할 수 있다. Polyglot은 다양한 다국어 애플리케이션을 지원하는 NLP 도구이다. 그것은 여러 40개 언어에 대한 NER, 여러 165개 언어에 대한 토큰화, 여러 196개 언어에 대한 언어 감지, 여러 136개 언어에 대한 심리 분석, 여러 16개의 언어에 대한 POS 태깅, 여러 135개 언어에 대한 형태학적 분석, 여러 137개 언어에 대한 삽입 단어와 여러 69개 언어에 대한 음역을 제공한다. MontyLingua는 영어 텍스트의 의미론적 해석을 수행하는 데 사용되는 NLP 도구이다. 영어 문장으로부터, 그것은 동사, 명사, 형용사, 날짜, 문구 등의 의미 정보를 추출한다.

문장은 로직을 사용하여 정식으로 표현될 수 있다. 명제 논리의 기본 표현이나 문장은 P, Q, R 등의 명제 기호를 사용하여 표시된다. 명제 논리에서 복잡한 표현식은 부울 연산자(Boolean operators)를 사용하여 표현할 수 있다. 예를 들어, 명제 논리를 사용하여 If it is raining, I'll wear a raincoat 문장을 표현한다.

-P: It is raining.
-Q: I'll wear raincoat.
-P→Q: If it is raining, I'll wear a raincoat.

Page 109.

NLTK에서 사용되는 연산자를 표현하기 위해 다음 코드를 살펴본다.

<소스>

WFF(Well-formed Formulas)는 명제 기호을 사용하거나 명제 기호 및 부울 연산자의 조합을 사용하여 형성된다.

다른 서브클래스로 논리적 표현을 분류하는 NLTK에서 다음 코드를 살펴보자.

<소스>

논리적 표현에 True 혹은 False 값을 매핑하는 경우, Valuation 함수는 NLTK에서 사용된다.

<소스>

Page 110.

2016.09.22

NLTK에서 상수 및 조건(predicates)을 포함하는 일차 술어 논리(First order predicate logic)는 다음 코드에서 확인한다.

<소스>

서명은 연관된 유형 및 비논리 상수를 매핑하는 NLTK에서 사용된다. 쿼리를 생성하고 데이터베이스에서 데이터를 검색하는 데 도움이 되는 NLTK에서 다음 코드를 살펴본다.

<소스>

Page 111.

<소스>

2016.09.23

NER 소개

NER(Named entity recognition)는 고유 명사(proper nouns) 혹은 명명된 개체(named entities)가 문서에 위치하는 과정이다. 그런 다음, 이 명명된 엔티티는 사람 이름, 위치, 조직등과 다른 범주로 분류하고 있다.

IIIT-Hyderabad IJCNLP 2008에 의해 정의된 12 NER의 tagsets이 있다.(확인) 이들은 여기에 설명된다.

<표>

Page 112.

<표>

NER의 애플리케이션 중 하나는 정보 추출이다. NLTK에서는 튜플(엔티티, 관계, 엔티티)를 저장함으로써 정보 추출하는 작업을 수행하고, 엔티티 값이 검색될 수 있다.

정보 추출이 수행되는 방법을 보여주는 NLTK의 예제를 고려한다.

<소스>

nltk.tag.stanford 모듈은 NER을 수행하기 위해 스탠포드 태거의 사용한다. http://nlp.stanford.edu/software에서 태거 모델을 다운로드 할 수 있다.

이제 스탠포드 태거를 사용하여 NER을 수행하기 위해 사용되는 NLTK에서 다음 예제를 살펴보자.

<소스>

분류기(classifier)는 명명된 엔티티를 감지하는 NLTK에서 훈련을 한다. 함수 nltk.ne.chunk() 사용으로, 명명된 엔티티는 텍스트에서 식별될 수 있다. 매개변수(파라미터) 바이너리가 true로 설정되어있는 경우, 명명된 엔티티는 감지되고 NE 태그로 태그된다. 그렇지 않으면 명명된 개체는 PERSON, GPE과 ORGANIZATION 같은 태그로 태그된다.

Page 113.

그들이 존재하는 경우, 명명된 엔티티 이름 검출하는 다음 코드를 살펴 보고 NE 태그로 태그한다.

<소스>

Page 114.

<소스>

명명된 개체를 검색하는 데 사용될 수 NLTK에서 또 다른 예제를 고려한다.

<소스>

Page 115.

chunker는 의미상 관련 단어의 순서로 평문을 분할하는데 사용되는 프로그램이다. NLTK에서 NER을 수행하려면, default chunkers가 사용된다. 디폴트 청커는 ACE 코퍼스에 훈련된 분류자에 따른 청거가 있다. 다른 chunkers는 파싱 혹은 청크된 NLTK 코포라(corpora)에 대한 교육을 한다. NLTK의 chunkers에 의해 덮여진 언어는 다음과 같다.

- 네델란드어
- 스페인어
- 포르투갈어
- 영어

명명된 엔티티를 식별하고 다른 명명된 엔티티 클래스로 분류되는 NLTK의 또 다른 예제를 살펴본다.

<소스>

2016.09.26

http://untitledtblog.tistory.com/97

Hidden Markov Model을 사용하는 NER 시스템

HMM은 NER의 인기있는 통계적 방법 중 하나이다. HMM은 명확한 확률 분포와 관련된 상태의 유한 집합으로 구성된 SFSA(Stochastic Finite State Automaton)로 정의된다. 상태(States)는 관찰되지 않거나 숨겨져 있다. HMM은 출력으로 최적의 상태 시퀀스를 생성한다. HMM은 마르코프 체인 속성을 기반으로 한다. 마르코프 체인 속성에 따라, 다음 상태의 발생 확률은 이전 태그에 의존한다. 구현하는 가장 간단한 방법이다. HMM의 단점은 많은 훈련이 필요하고 큰 의존성으로 사용될 수 없다는 것이다. HMM은 다음과 같이 구성된다.

-상태 세트, S, |S|=N(확인) 여기서, N은 상태의 총 숫자이다.
-시작 상태, S0

Page 116.

-출력 알파벳, O. |O|=k. k는 출력 알파벳의 총 개수이다.
-전이 확률, A
-출력 확률, B
-초기 상태 확률, π

HMM은 다음 튜플로 표시된다.-λ = (A, B, π)

시작 혹은 초기 상태 확률은 특정 태그가 문장에서 먼저 발생하는 확률로 정의될 수 있다.

전이 확률(A=aij)은 현재 특정 태그 i의 발생을 주어진 문장에서 다음 태그 j의 발생 확률로 정의될 수 있다.

A=aij= 상태 si에서 sj까지의 전환의 수/상태 si에서 전환의 수.

출력 확률(B=bj(O))은 상태 j에서 주어진 출력 시퀀스의 발생 확률로 정의될 수 있다.  
