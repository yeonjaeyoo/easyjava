Page 107.

6장. 의미 분석-Meaning Matters

의미 분석, 혹은 의미 생성은 NLP의 작업 중 하나이다. 문자 시퀀스 혹은 단어 시퀀스의 의미를 결정하는 과정으로 정의된다. 명료화 작업을 수행하기 위해 사용될 수 있다.

6장에서는 다음 주제를 살펴볼 것이다.

-NER
-HMM을 사용한 NER 시스템
-기계 학습 툴킷(machine learning toolkits)을 사용한 NER 훈련
-POS 태깅(POS tagging)을 사용한 NER
-Wordnet에서 synset id의 생성
-Wordnet을 사용한 명확한 감각(Disambiguating senses)

Page 108.

의미 분석 소개

NLP는 자연어에 대한 실행할 수 있는 계산을 의미한다. 자연어 처리하는 동안에 수행되는 단계 중 하나는 의미론적 분석이다. 입력 문장을 분석하는 동안, 문장의 구문 구조가 설계되면, 이 후에 문장의 의미 분석이 수행된다. 의미분석 해석은 문장에서 의미를 매핑하는 것을 의미한다.(확인) 콘텐츠 해석(Contextual interpretation)은 지식 표현의 논리 형태를 매핑한다. 의미론적 분석의 원시 혹은 기본 단위는 의미 혹은 감각으로 지칭된다. 감각을 다루는 도구 중 하나는 ELIZA이다. ELIZA는 조셉 바이첸바움(Joseph Weizenbaum)에 의해 60년대에 개발됐다. 치환과 문장을 분석하는 패턴 매칭 기술을 사용하고 주어진 입력에 출력을 제공한다. MARGIE는 70년대에 Robert Schank에 의해 개발됐다. 그것은 11 프리미티브(primitives)를 사용하여 모든 영어 동사를 나타낼 수 있다. MARGIE는 문장의 의미를 해석하고 프리미티브의 도움을 나타낼 수 있다. 그것은 게다가 스크립트의 개념에게 방법을 주었다. MARGIE에서 SAM(Script Applier Mechanism)이 개발됐다. 그것은 영어, 중국어, 러시아어, 네덜란드어, 스페인어 같은 다양한 언어의 문장을 번역할 수 있다. 텍스트 데이터에 대한 처리를 수행하기 위해, Python library 혹은 TextBlob이 사용된다. TextBlob는 품사 태깅, 명사구 추출, 분류, 기계 번역, 심리 분석과 같은 NLP 작업을 수행하기 위한 API를 제공한다.

의미 분석은 데이터베이스를 조회하고 정보를 검색하는 데 사용할 수 있다. 또 다른 파이썬 라이브러리(Python library), Gensim는 문서 인덱싱, 주제 모델링 및 유사도 검색을 수행하는데 사용할 수 있다. Polyglot은 다양한 다국어 애플리케이션을 지원하는 NLP 도구이다. 그것은 여러 40개 언어에 대한 NER, 여러 165개 언어에 대한 토큰화, 여러 196개 언어에 대한 언어 감지, 여러 136개 언어에 대한 심리 분석, 여러 16개의 언어에 대한 POS 태깅, 여러 135개 언어에 대한 형태학적 분석, 여러 137개 언어에 대한 삽입 단어와 여러 69개 언어에 대한 음역을 제공한다. MontyLingua는 영어 텍스트의 의미론적 해석을 수행하는 데 사용되는 NLP 도구이다. 영어 문장으로부터, 그것은 동사, 명사, 형용사, 날짜, 문구 등의 의미 정보를 추출한다.

문장은 로직을 사용하여 정식으로 표현될 수 있다. 명제 논리의 기본 표현이나 문장은 P, Q, R 등의 명제 기호를 사용하여 표시된다. 명제 논리에서 복잡한 표현식은 부울 연산자(Boolean operators)를 사용하여 표현할 수 있다. 예를 들어, 명제 논리를 사용하여 If it is raining, I'll wear a raincoat 문장을 표현한다.

-P: It is raining.
-Q: I'll wear raincoat.
-P→Q: If it is raining, I'll wear a raincoat.

Page 109.

NLTK에서 사용되는 연산자를 표현하기 위해 다음 코드를 살펴본다.

<소스>

WFF(Well-formed Formulas)는 명제 기호을 사용하거나 명제 기호 및 부울 연산자의 조합을 사용하여 형성된다.

다른 서브클래스로 논리적 표현을 분류하는 NLTK에서 다음 코드를 살펴보자.

<소스>

논리적 표현에 True 혹은 False 값을 매핑하는 경우, Valuation 함수는 NLTK에서 사용된다.

<소스>

Page 110.

2016.09.22

NLTK에서 상수 및 조건(predicates)을 포함하는 일차 술어 논리(First order predicate logic)는 다음 코드에서 확인한다.

<소스>

서명은 연관된 유형 및 비논리 상수를 매핑하는 NLTK에서 사용된다. 쿼리를 생성하고 데이터베이스에서 데이터를 검색하는 데 도움이 되는 NLTK에서 다음 코드를 살펴본다.

<소스>

Page 111.

<소스>

2016.09.23

NER 소개

NER(Named entity recognition)는 고유 명사(proper nouns) 혹은 명명된 개체(named entities)가 문서에 위치하는 과정이다. 그런 다음, 이 명명된 엔티티는 사람 이름, 위치, 조직등과 다른 범주로 분류하고 있다.

IIIT-Hyderabad IJCNLP 2008에 의해 정의된 12 NER의 tagsets이 있다.(확인) 이들은 여기에 설명된다.

<표>

Page 112.

<표>

NER의 애플리케이션 중 하나는 정보 추출이다. NLTK에서는 튜플(엔티티, 관계, 엔티티)를 저장함으로써 정보 추출하는 작업을 수행하고, 엔티티 값이 검색될 수 있다.

정보 추출이 수행되는 방법을 보여주는 NLTK의 예제를 고려한다.

<소스>

nltk.tag.stanford 모듈은 NER을 수행하기 위해 스탠포드 태거의 사용한다. http://nlp.stanford.edu/software에서 태거 모델을 다운로드 할 수 있다.

이제 스탠포드 태거를 사용하여 NER을 수행하기 위해 사용되는 NLTK에서 다음 예제를 살펴보자.

<소스>

분류기(classifier)는 명명된 엔티티를 감지하는 NLTK에서 훈련을 한다. 함수 nltk.ne.chunk() 사용으로, 명명된 엔티티는 텍스트에서 식별될 수 있다. 매개변수(파라미터) 바이너리가 true로 설정되어있는 경우, 명명된 엔티티는 감지되고 NE 태그로 태그된다. 그렇지 않으면 명명된 개체는 PERSON, GPE과 ORGANIZATION 같은 태그로 태그된다.

Page 113.

그들이 존재하는 경우, 명명된 엔티티 이름 검출하는 다음 코드를 살펴 보고 NE 태그로 태그한다.

<소스>

Page 114.

<소스>

명명된 개체를 검색하는 데 사용될 수 NLTK에서 또 다른 예제를 고려한다.

<소스>

Page 115.

chunker는 의미상 관련 단어의 순서로 평문을 분할하는데 사용되는 프로그램이다. NLTK에서 NER을 수행하려면, default chunkers가 사용된다. 디폴트 청커는 ACE 코퍼스에 훈련된 분류자에 따른 청거가 있다. 다른 chunkers는 파싱 혹은 청크된 NLTK 코포라(corpora)에 대한 교육을 한다. NLTK의 chunkers에 의해 덮여진 언어는 다음과 같다.

- 네델란드어
- 스페인어
- 포르투갈어
- 영어

명명된 엔티티를 식별하고 다른 명명된 엔티티 클래스로 분류되는 NLTK의 또 다른 예제를 살펴본다.

<소스>

2016.09.26

http://untitledtblog.tistory.com/97

Hidden Markov Model을 사용하는 NER 시스템

HMM은 NER의 인기있는 통계적 방법 중 하나이다. HMM은 명확한 확률 분포와 관련된 상태의 유한 집합으로 구성된 SFSA(Stochastic Finite State Automaton)로 정의된다. 상태(States)는 관찰되지 않거나 숨겨져 있다. HMM은 출력으로 최적의 상태 시퀀스를 생성한다. HMM은 마르코프 체인 속성을 기반으로 한다. 마르코프 체인 속성에 따라, 다음 상태의 발생 확률은 이전 태그에 의존한다. 구현하는 가장 간단한 방법이다. HMM의 단점은 많은 훈련이 필요하고 큰 의존성으로 사용될 수 없다는 것이다. HMM은 다음과 같이 구성된다.

-상태 세트, S, |S|=N(확인) 여기서, N은 상태의 총 숫자이다.
-시작 상태, S0

Page 116.

-출력 알파벳, O. |O|=k. k는 출력 알파벳의 총 개수이다.
-전이 확률, A
-출력 확률, B
-초기 상태 확률, π

HMM은 다음 튜플로 표시된다.-λ = (A, B, π)

시작 혹은 초기 상태 확률은 특정 태그가 문장에서 먼저 발생하는 확률로 정의될 수 있다.

전이 확률(A=aij)은 현재 특정 태그 i의 발생을 주어진 문장에서 다음 태그 j의 발생 확률로 정의될 수 있다.

A=aij= 상태 si에서 sj까지의 전환의 수/상태 si에서 전환의 수.

출력 확률(B=bj(O))은 상태 j에서 주어진 출력 시퀀스의 발생 확률로 정의될 수 있다.  

2016.09.27

B=bj(k)= 상태 j의 횟수(the number of times) 및 관찰하는 심벌 k/상태 j에서 예상되는 j의 횟수(확인)

바움 웰치(Baum Welch) 알고리즘은 최대 우도와 HMM 파라미터의 후방 모드 평가를 찾기 위해 사용된다. 전후 알고리즘(forward-backward algorithm)은 주어진 배출 혹은 관측의 시퀀스를 모든 숨겨진 상태 변수의 사후 marginals를 찾기 위해 사용된다.(확인)

HMM-주석, HMM 기차 및 HMM 테스트를 사용한 NER을 수행에 관련된 세 가지 단계가 있다. 주석 모듈은 주석 혹은 학습 가능한 데이터로 로우 텍스트를 변환한다. HMM 트레인 동안에, HMM 파라미터를 계산한다.- 스타트 확률, 전이 확률 및 출력 확률 . HMM 테스트 동안에, 비터비(Viterbi) 알고리즘을 사용한다. 최적의 태그 순서를 발견한다.

NLTK에서 HMM을 사용한 청크의 예제를 살펴본다. 청킹을 사용하여, NP 및 VP 청크를 획득할 수 있다. NP 청크는 더 나아가서 고유 명사 혹은 명명된 엔티티를 획득하도록 처리될 수 있다.

<소스>

Page 117.

<소스>

Page 118.

<소스>

Page 119.

<소스>

Page 120.

<소스>

Page 121.

NER 태거의 결과는 response와 answer key로 인간의 해석으로 정의될 수 있다. 그래서 다음과 같은 정의를 제공한다.

-Correct: 응답은 정확하게 응답 키와 동일한 경우
-Incorrect: 응답은 응답 키와 같지 않으면
-Missing: 응답 키는 태그가 발견되지만 응답은 태그되지 않은 경우
-Spurious: 응답이 태그를 찾지만 응답 키는 태그되지 않는다.

NER 기반 시스템의 성능은 다음과 같은 매개변수를 사용하여 판단할 수 있다.

Precision (P): 다음과 같이 정의된다.
P=Correct/(Correct+Incorrect+Missing)

Recall (R): 다음과 같이 정의된다.
R=Correct/ (Correct+Incorrect+Spurious)

F-Measure: 다음과 같이 정의된다.
F-Measure = (2*PREC*REC)/(PRE+REC)

기계 학습 툴킷(Machine Learning Toolkits)을 사용한 트레이닝 NER

NER은 다음 방법을 사용하여 수행할 수 있다. 

-규칙 기반 혹은 손수(Handcrafted) 접근
-목록 조회 방법(List Lookup approach)
-언어 접근(Linguistic approach)

-기계 학습 기반의 접근 방식 혹은 자동화된 접근 방식
-은닉 마르코프 모델(Hidden Markov Model)
-최대 엔트로피 마르코프 모델(Maximum Entropy Markov Model)
-조건부 랜덤 필드(Conditional Random Fields)
-서포트 벡터 머신(Support Vector Machine)
-의사 결정 트리(Decision Trees)

그것은 실험적으로 기계 학습 기반의 접근 방식이 규칙 기반 접근 방식보다 뛰어나다는 것을 증명한다.(확인) 규칙 기반 접근법과 기계 학습 기반 방법의 조합이 사용되는 경우에도, 이 후 NET의 성능은 증가할 것이다.

2016.09.28

Page 122.

POS 태깅을 사용한 NER

POS 태깅을 사용하여, NER은 수행할 수 있다. 사용할 수있는 POS 태그는 다음과 같다. https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html에서 사용 가능하다.

<표>

Page 123.

POS 태깅이 수행되면, 이 후 POS 정보를 사용하여, 지명된 엔티티는 식별할 수 있다. NNP 태그로 태그된 토큰은 지명된 엔티티이다.

POS 태그가 NER을 수행하는 데 사용되는 NLTK에 다음과 같은 예제를 살펴본다.

<소스>

여기, 그들이 NNP 태그로 지정된 이후로 명명된 개체는-존, 스미스, 뉴욕, 독일.(확인)

이제 POS 태깅은 NLTK에서 수행되고, POS 태그 정보가 명명된 엔티티를 검색하는 데 사용되는 또 다른 예제를 살펴보자.

<소스>

Page 124.

<소스>

여기서 존은 NP 태그가 지정되어 있으므로, 명명된 개체로 식별된다. 이 토큰은 훈련되지 않았기 때문에 여기에 토큰의 일부는 None 태그가 지정된다.

Wordnet에서 synset id의 생성

워드넷(Wordnet)은 영어 어휘 데이터베이스로 정의할 수 있다. 상위어(hypernym), 동의어, 반의어, 그리고 하위 분류 같은 단어 간의 개념 의존성은 synset을 사용하여 찾을 수 있다.

synsets의 생성에 대한 NLTK에서 다음 코드를 살펴본다.

<소스>

Page 125.

<소스>

이제 synset을 사용하여 단어를 검색하는 데 사용되는 NLTK의 다음 코드를 살펴보자.

<소스>

Page 126.

<소스>

여기서, cat.n.01은 cat 명사 범주와 cat이 존재의 하나의 의미를 의미한다.(확인)

<소스>

이제 Synsets의 사용과 ISO 639 언어 코드를 사용한 Open Multilingual Wordnet을 묘사한 NLTK에서 다음 예제를 살펴보자.

<소스>

Page 127.

<소스>

Wordnet을 사용한 명확한 감각

모호성은 감각 혹은 의미에 기초하여, 둘 이상의 동일한 철자 혹은 동일한 소리 단어를 구별하는 작업이다.

파이썬 기술을 사용하여 명료화 혹은 WSD 작업의 구현은 다음과 같다.

