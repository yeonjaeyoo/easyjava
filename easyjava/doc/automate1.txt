1. 웹 작업

인터넷없는 삶을 상상해본 적이 있을까? 음식 주문에 대한 정보를 교환하는 것부터 거의 모든 것이 오늘날 인터넷에 크게 의존한다. 흥미로운 World Wide Web의 세계를 살펴보고 파이썬(Python) 모듈을 사용하여 상호 작용할 수 있는 다양한 방법을 살펴보자.

1장에서는 다음 내용을 살펴본다.

-HTTP 요청생성
-웹 스크래핑(web scraping)에 대한 간략한 설명
-웹 컨텐츠(web content) 파싱(Parsing) 및 추출(extracting)
-웹 컨텐츠 다운로드
-서드 파티(third-party) REST API 작업
-파이썬의 비동기 HTTP 서버
-셀레늄 바인딩(selenium bindings)을 사용한 웹 자동화
-웹 스크래핑과 리드 생성 자동화

소개

인터넷은 삶을 매우 쉽게 만들어주기 때문에 때로는 그 힘을 깨닫지 못한다. 친구 상태를 확인, 부모님 전화, 중요한 비즈니스 이메일(e-mail)에 응답하거나 게임을 하는 등- 오늘날 거의 모든 일에 대해 WWW(World Wide Web)를 사용한다.

Page 13.

이 레시피를 실행하려면 파이썬 v2.7을 설치해야한다. 일단 설치되면 파이썬 pip를 설치해야한다. PIP는 Pip Installs Packages의 약자로 컴퓨터에 필요한 파이썬 패키지를 다운로드하고 설치하는 데 사용할 수 있는 프로그램이다. 마지막으로 HTTP 요청을 하기 위해 requests 모듈이 필요하다.

requests 모듈을 설치하여 시작할 것이다(운영 체제를 기반으로 머신에서 수행할 수 있도록 파이썬 및 pip 설치를 남겨둘 것이다). 다른 전제 조건은 없다. 이제, 서둘러서 시작하자.

사용 방법

1. Linux/Mac 컴퓨터에서 터미널(Terminal)로 이동하여 다음 커맨드를 실행한다.

pip install -U requests

파이썬 사이트 패키지에 대한 권한이 없는 경우 sudo만 사용해야한다. 그렇지 않으면 sudo가 필요하지않다.(확인)

2. 다음 코드는 파이썬의 requests 모듈에서 HTTP GET 요청을하는 데 도움이 된다.

import requests r =
requests.get('http://ip.jsontest.com/')
print("Response object:", r)
print("Response Text:", r.text)

3. 다음 출력을 확인한다.

<그림>

Page 14.

4. 데이터 페이로드(data payload)로 HTTP GET 요청을 생성하는 것은 요청에서 간단하다. 다음 코드는 이를 달성하는 데 도움이 된다. 전송될 URL 요청을 확인할 수도 있다.

payload = {'q': 'chetan'} r =
requests.get('https://github.com/search', params=payload)
print("Request URL:", r.url)

<그림>

5. 이제 requests 모듈을 사용하여 HTTP POST 호출을 생성해보자. 이는 웹 사이트에 로그인 혹은 가입 양식을 채우고 포스트(POST) 하는 것과 유사하다.

payload = {'key1': 'value1'} r =
requests.post("http://httpbin.org/post", data=payload)
print("Response text:", r.json())

<그림>

Page 15.

오류(errors) 및 예외 처리(exceptions)는 요청에 대해서도 매우 편리하다. 다음 단편적인 코드는 오류 처리의 예제를 보여준다. 머신에서 인터넷 연결없이 코드를 실행하면 예외가 발생한다. 예외 처리기(exception handler)는 예외를 캐치(catch)하고 예상대로 새 연결을 설정하지 못했다.(확인)

try:
    r = requests.get("http://www.google.com/")
except requests.exceptions.RequestException as e:
    print("Error Response:", e.message)

어떻게 작동 하는가?

이 레시피에서는 파이썬의 requests 모듈을 사용하여 다양한 유형의 HTTP 요청을 생성하는 방법을 살펴본다. 이 코드가 어떻게 작동하는지 살펴보자.

- 첫 번째 예제에서는 http://ip.jsontest.com에 GET 요청을 전송하고 응답 코드와 응답 텍스트를 받았다. 인터넷에서 컴퓨터의 현재 IP 주소를 반환한다.
- 두 번째 예제에서는 페이로드 데이터로 HTTP GET 요청을 수행했다.    

2017.03.09

웹 스크래핑(web scraping) 살펴보기

웹 스크래핑을 수행하는 방법을 배우기 전에 스크래핑의 의미를 이해하자. 웹 세계에서 스크래핑은 컴퓨터 프로그램의 도움으로 상기 포맷으로 필요한 정보를 추출하려는 의도로 웹 사이트의 페이지를 가려내는 방법이다. 예를 들어 블로그에 게시된 모든 기사의 제목과 날짜를 가져 오려면 블로그를 통해 긁어 모으고 필요한 데이터를 가져오고, 요청에 기반이 되는 데이터베이스(database) 혹은 플랫 파일(flat file)에 저장하는 프로그램을 생성할 수 있다.

웹 스크래핑(Web scraping)은 종종 웹 크롤링(web crawling)과 혼동된다. 웹 크롤러(web crawler)는 웹 인덱싱의 목적으로 웹을 체계적으로 탐색하고 사용자가 웹을보다 효과적으로 검색할 수 있도록 웹 페이지 색인을 위한 검색 엔진에서 사용되는 봇이다.

그러나 스크래핑은 쉽지 않다. 우리에게 흥미로운 데이터는 XML 태그 혹은 HTML 태그에 포함된 특정 형식의 블로그 혹은 웹 사이트에서 사용할 수 있다. 따라서 필요한 데이터를 추출하기 전에 형식을 알아야 한다. 또한 웹 스크래퍼는 추출된 데이터를 나중에 처리하기 위해 저장해야하는 형식을 알아야한다. 브라우저 표시가 같을지라도 HTML 혹은 XML 형식이 변경되면 스크래핑 코드는 실패한다는 것을 이해하는 것도 중요하다.

2017.03.10

웹 스크래핑의 적법성

웹 스크래핑은 항상 법적인 측면에서 스캐너 아래에 있었다. 웹 스크래핑을 할 수 있을까? 법적 혹은 윤리적인 방법은 무엇인가? 수익 창출을 위해 스크래핑으로 확보한 데이터를 사용할 수 있을까?

이 주제는 많은 논의를 거쳤지만, 웹에서 저작권 정보를 스크랩하거나, 컴퓨터 사기 및 남용 방지법을 위반하거나, 웹 사이트의 서비스 약관을 위반하면 웹 스크래핑 관련 문제가 발생할 수 있다. 예를 들어, 공개 데이터를 가져 오기 위해 웹을 스크래핑하고 있다면 여전히 괜찮을 것이다. 그러나 그것은 매우 문맥적이며 사용자가 스크래핑하는 것과 데이터를 사용하는 방법에 대해 주의해야 한다.

Page 17.

다음은 데이터 스크래핑에 대한 웹의 몇 가지 지침이다.

-https://en.wikipedia.org/wiki/Web_scraping#Legal_issues
-https://www.quora.com/What-is-the-legality-of-web-scraping

Getting ready

https://github.com/ 웹 사이트에서 가격 데이터를 사용하여 파이썬으로 웹 스크래핑을 살펴본다. 이것은 매우 사소한 예제이지만 스크래핑 하는 데 걸리는 시간을 단축시킨다. 이 파이썬 레시피를 사용하여 흥미로운 데이터를 시작하고 스크랩하자.

How to do it

1. 컴퓨터에서 구글 크롬 브라우저를 실행시키고 https://github.com/pricing/ 웹 페이지를 연다. 이 페이지에서는 개인(Personal), 조직(Organization) 및 엔터프라이즈(Enterprise)와 같은 여러 가지 가격 정책을 확인할 수 있다.
2. 이제 브라우저에서 Personal 계획의 가격을 마우스 오른쪽 버튼으로 클릭하고 다음 스크린 샷처럼 Inspect 요소를 클릭한다.

<그림>

Page 18.

